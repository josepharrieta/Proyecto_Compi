"""
Analizador L√©xico para Olympiac
=========================================

Este m√≥dulo implementa un analizador l√©xico (lexer) para un lenguaje de dominio espec√≠fico
orientado a la gesti√≥n de deportistas y competencias. El analizador identifica y clasifica
tokens en el c√≥digo fuente, incluyendo declaraciones, tipos de datos, estructuras de control,
funciones y operadores.

Autores: [Kevin N√∫√±ez, Axel L√≥pez, Felipe Murillo, Joseph Arrieta, Arturo Chavarr√≠a]
Fecha: Octubre 2025
Versi√≥n: 1.0

Dependencias:
- enum: Para definir tipos de componentes l√©xicos
- re: Para procesamiento de expresiones regulares

"""

from enum import Enum, auto
import re


class TipoToken(Enum):
    """
    Enumeraci√≥n que define todos los tipos de tokens que puede reconocer el analizador l√©xico.
    
    Cada tipo representa una categor√≠a sint√°ctica espec√≠fica del lenguaje deportivo:
    - COMENTARIO: L√≠neas que inician con ';'
    - PALABRA_CLAVE: Palabras reservadas del lenguaje
    - DECLARACION_ENTIDAD: Declaraciones de entidades (Deportista, Lista)
    - TIPO_DATO_DOMINIO: Tipos espec√≠ficos del dominio (Pais, Deporte, Resultado)
    - ESTRUCTURA_CONTROL_FLUJO: Elementos de control de flujo (si, entonces, repetir)
    - INVOCACION_FUNCION: Llamadas a funciones del sistema
    - OPERADOR_ARITMETICO: Operadores matem√°ticos (+, -, *, /, %)
    - OPERADOR_COMPARACION: Operadores de comparaci√≥n (==, !=, >, <, >=, <=)
    - OPERADOR_ESPECIAL: Operadores especiales como 'vs'
    - LITERAL_CADENA: Cadenas de texto entre comillas
    - NOMBRE_IDENTIFICADOR: Nombres de variables y entidades
    - NUMERO_ENTERO: Valores num√©ricos enteros
    - NUMERO_DECIMAL: Valores num√©ricos con decimales
    - VALOR_BOOLEANO: Valores True/False
    - SIMBOLO_PUNTUACION: S√≠mbolos de puntuaci√≥n y delimitadores
    - RESULTADO_ADICIONAL: Tokens espec√≠ficos para resultados (listaRes)
    - CONDICION_EMPATE: Token espec√≠fico para empates
    - ESPACIOS_BLANCOS: Espacios, tabs y otros caracteres de espacio
    - TOKEN_NO_RECONOCIDO: Tokens que no coinciden con ning√∫n patr√≥n
    """
    COMENTARIO = auto()
    PALABRA_CLAVE = auto()
    DECLARACION_ENTIDAD = auto()
    TIPO_DATO_DOMINIO = auto()
    ESTRUCTURA_CONTROL_FLUJO = auto()
    INVOCACION_FUNCION = auto()
    OPERADOR_ARITMETICO = auto()
    OPERADOR_COMPARACION = auto()
    OPERADOR_ESPECIAL = auto()
    LITERAL_CADENA = auto()
    NOMBRE_IDENTIFICADOR = auto()
    NUMERO_ENTERO = auto()
    NUMERO_DECIMAL = auto()
    VALOR_BOOLEANO = auto()
    SIMBOLO_PUNTUACION = auto()
    RESULTADO_ADICIONAL = auto()
    CONDICION_EMPATE = auto()
    ESPACIOS_BLANCOS = auto()
    TOKEN_NO_RECONOCIDO = auto()


class TokenLexico:
    """
    Representa un token l√©xico individual encontrado durante el an√°lisis.
    
    Atributos:
        tipo_token (TipoToken): El tipo de token identificado
        texto_original (str): El texto exacto del token en el c√≥digo fuente
        informacion_adicional (str): Informaci√≥n sem√°ntica adicional sobre el token
        numero_linea (int): L√≠nea donde se encontr√≥ el token (opcional)
        posicion_columna (int): Columna donde inicia el token (opcional)
    """
    
    def __init__(self, tipo_token, texto_original, informacion_adicional="", numero_linea=0, posicion_columna=0):
        """
        Inicializa un nuevo token l√©xico.
        
        Argumentos:
            tipo_token (TipoToken): El tipo de token identificado
            texto_original (str): El texto exacto del token
            informacion_adicional (str, optional): Informaci√≥n sem√°ntica adicional. Por defecto "".
            numero_linea (int, optional): N√∫mero de l√≠nea. Por defecto 0.
            posicion_columna (int, optional): Posici√≥n de columna. Por defecto 0.
        """
        self.tipo_token = tipo_token
        self.texto_original = texto_original
        self.informacion_adicional = informacion_adicional
        self.numero_linea = numero_linea
        self.posicion_columna = posicion_columna

    def __str__(self):
        """
        Representaci√≥n en cadena del token para depuraci√≥n y visualizaci√≥n.
        
        Salida:
            str: Representaci√≥n formateada del token en el formato requerido
        """
        return f'<"{self.tipo_token.name}", "{self.texto_original}", "{self.informacion_adicional}">'

    def __repr__(self):
        """
        Representaci√≥n t√©cnica del token para depuraci√≥n.
        
        Salida:
            str: Representaci√≥n t√©cnica del token
        """
        return f"TokenLexico({self.tipo_token}, '{self.texto_original}', '{self.informacion_adicional}')"


class AnalizadorLexico:
    """
    Analizador l√©xico principal para el lenguaje deportivo.
    
    Este analizador procesa c√≥digo fuente l√≠nea por l√≠nea, identificando y clasificando
    cada token seg√∫n patrones de expresiones regulares predefinidos. Mantiene una lista
    de todos los tokens encontrados y proporciona m√©todos para su an√°lisis y visualizaci√≥n.
    
    Atributos:
        codigo_fuente_lineas (list): Lista de l√≠neas del c√≥digo fuente a analizar
        tokens_encontrados (list): Lista de todos los tokens identificados
        patrones_reconocimiento (list): Patrones regex para cada tipo de token
        contador_errores_lexicos (int): N√∫mero de errores l√©xicos encontrados
    """
    patrones_reconocimiento = [
        (TipoToken.COMENTARIO, r'^;.*', "Comentario de l√≠nea completa"),
        (TipoToken.DECLARACION_ENTIDAD, r'^(Deportista|Lista)', "Declaraci√≥n de entidad del dominio"),
        (TipoToken.TIPO_DATO_DOMINIO, r'^(Pais|Deporte|Resultado)', "Tipo de dato espec√≠fico del dominio"),
        (TipoToken.ESTRUCTURA_CONTROL_FLUJO,r'^(RepetirHasta|FinRepHast|Repetir|FinRep|si|entonces|sino|endif)\b', "Estructura de control de flujo"),
        (TipoToken.INVOCACION_FUNCION, r'^(narrar\(|Comparar\(|input\()', "Invocaci√≥n de funci√≥n del sistema"),
        (TipoToken.PALABRA_CLAVE, r'^(preparacion|finprep|InicioCarrera|correr|finCarr|InicioRutina|ejecutar|finRuti|finact|ceremonia_medallas|competencia_oficial|partido_clasificatorio)', "Palabras clave del dominio"),
        (TipoToken.RESULTADO_ADICIONAL, r'^(listaRes)', "Token espec√≠fico para listas de resultados"),
        (TipoToken.CONDICION_EMPATE, r'^(empate)', "Token espec√≠fico para condiciones de empate"),
        (TipoToken.OPERADOR_COMPARACION, r'^(==|!=|>=|<=|>|<)', "Operador de comparaci√≥n l√≥gica"),
        (TipoToken.OPERADOR_ESPECIAL, r'^(vs)', "Operador especial vs"),
        (TipoToken.OPERADOR_ARITMETICO, r'^(\+|-|\*|/|%)', "Operador aritm√©tico b√°sico"),
        (TipoToken.NUMERO_ENTERO, r'^([0-9]+)', "N√∫mero entero positivo"),
        (TipoToken.VALOR_BOOLEANO, r'^(True|False)', "Valor l√≥gico booleano"),
        (TipoToken.NOMBRE_IDENTIFICADOR, r'^(\w+)', "Identificador v√°lido"),
        (TipoToken.SIMBOLO_PUNTUACION, r'^([(),;:{}\[\]\.-])', "S√≠mbolo de puntuaci√≥n o delimitador"),
        (TipoToken.ESPACIOS_BLANCOS, r'^(\s)+', "Espacios en blanco y caracteres de formato")
    ]

    def __init__(self, codigo_fuente_lineas):
        """
        Inicializa el analizador l√©xico con el c√≥digo fuente a procesar.
        
        Entradas:
            codigo_fuente_lineas (list): Lista de cadenas, cada una representando una l√≠nea de c√≥digo
        """
        self.codigo_fuente_lineas = codigo_fuente_lineas
        self.tokens_encontrados = []
        self.contador_errores_lexicos = 0

    def analizar_codigo_completo(self):
        """
        Realiza el an√°lisis l√©xico completo de todas las l√≠neas del c√≥digo fuente.
        
        Procesa cada l√≠nea secuencialmente, identifica todos los tokens y los almacena
        en la lista de tokens encontrados. Tambi√©n cuenta los errores l√©xicos encontrados.
        
        Salida:
            int: N√∫mero total de tokens v√°lidos encontrados (excluyendo espacios en blanco)
        """
        self.tokens_encontrados.clear()
        self.contador_errores_lexicos = 0
        
        for numero_linea, linea_codigo in enumerate(self.codigo_fuente_lineas, 1):
            tokens_linea = self._procesar_linea_individual(linea_codigo, numero_linea)
            self.tokens_encontrados.extend(tokens_linea)
        
        tokens_validos = [t for t in self.tokens_encontrados if t.tipo_token != TipoToken.ESPACIOS_BLANCOS]
        return len(tokens_validos)

    def mostrar_tokens_encontrados(self):
        """
        Imprime todos los tokens encontrados durante el an√°lisis en el formato requerido.
        
        Muestra cada token con su tipo, texto original e informaci√≥n adicional.
        Excluye los espacios en blanco para una salida m√°s limpia.
        """
        tokens_mostrar = [token for token in self.tokens_encontrados 
                        if token.tipo_token != TipoToken.ESPACIOS_BLANCOS]
        
        for token in tokens_mostrar:
            print(token)

    def _procesar_linea_individual(self, linea_codigo, numero_linea):
        """
        Procesa una l√≠nea individual del c√≥digo fuente y extrae todos sus tokens.
        
        Entradas:
            linea_codigo (str): La l√≠nea de c√≥digo a procesar
            numero_linea (int): N√∫mero de l√≠nea para referencia de errores
            
        Salida:
            list: Lista de tokens encontrados en la l√≠nea
        """
        tokens_linea = []
        posicion_actual = 0
        linea_limpia = linea_codigo.rstrip()

        while posicion_actual < len(linea_limpia):
            segmento_restante = linea_limpia[posicion_actual:]
            token_encontrado = False

            for tipo_token, patron_regex, descripcion in self.patrones_reconocimiento:
                coincidencia = re.match(patron_regex, segmento_restante)
                
                if coincidencia:
                    texto_token = coincidencia.group()
                    
                    if tipo_token != TipoToken.ESPACIOS_BLANCOS:
                        informacion_semantica = self._extraer_informacion_semantica(tipo_token, texto_token)
                        nuevo_token = TokenLexico(
                            tipo_token, 
                            texto_token, 
                            informacion_semantica,
                            numero_linea,
                            posicion_actual + 1  # Columna inicia en 1
                        )
                        tokens_linea.append(nuevo_token)
                    
                    posicion_actual += coincidencia.end()
                    token_encontrado = True
                    break

            if not token_encontrado:
                caracter_problematico = segmento_restante[0]
                try:
                    caracter_mostrable = repr(caracter_problematico)
                except:
                    caracter_mostrable = f"ord({ord(caracter_problematico)})"
                
                print(f"ERROR L√âXICO: Car√°cter no reconocido {caracter_mostrable} "
                      f"en l√≠nea {numero_linea}, columna {posicion_actual + 1}")
                self.contador_errores_lexicos += 1
                posicion_actual += 1

        return tokens_linea

    def _extraer_informacion_semantica(self, tipo_token, texto_token):
        """
        Extrae informaci√≥n sem√°ntica adicional basada en el tipo y contenido del token.
        
        Entradas:
            tipo_token (TipoToken): El tipo de token identificado
            texto_token (str): El texto original del token
            
        Salida:
            str: Informaci√≥n sem√°ntica adicional sobre el token
        """
        if tipo_token == TipoToken.NUMERO_ENTERO:
            try:
                valor_numerico = int(texto_token)
                return f"Valor num√©rico: {valor_numerico}"
            except ValueError:
                return "Error al convertir n√∫mero entero"
                
        elif tipo_token == TipoToken.NUMERO_DECIMAL:
            try:
                valor_decimal = float(texto_token)
                return f"Valor decimal: {valor_decimal}"
            except ValueError:
                return "Error al convertir n√∫mero decimal"
                
        elif tipo_token == TipoToken.LITERAL_CADENA:
            contenido_cadena = texto_token.strip('"')
            return f"Contenido de cadena: '{contenido_cadena}'"
            
        elif tipo_token == TipoToken.NOMBRE_IDENTIFICADOR:
            return "Identificador v√°lido de usuario"
            
        elif tipo_token == TipoToken.INVOCACION_FUNCION:
            return "Funci√≥n del sistema invocada"
            
        elif tipo_token == TipoToken.OPERADOR_ARITMETICO:
            operadores_descripcion = {
                '+': 'suma', '-': 'resta', '*': 'multiplicaci√≥n', 
                '/': 'divisi√≥n', '%': 'm√≥dulo'
            }
            return f"Operador de {operadores_descripcion.get(texto_token, 'desconocido')}"
            
        elif tipo_token == TipoToken.OPERADOR_COMPARACION:
            comparadores_descripcion = {
                '==': 'igualdad', '!=': 'desigualdad', '>': 'mayor que',
                '<': 'menor que', '>=': 'mayor o igual', '<=': 'menor o igual'
            }
            return f"Comparador de {comparadores_descripcion.get(texto_token, 'desconocido')}"
            
        elif tipo_token == TipoToken.OPERADOR_ESPECIAL:
            return f"Operador especial: {texto_token}"
            
        elif tipo_token == TipoToken.VALOR_BOOLEANO:
            return f"Valor l√≥gico: {texto_token}"
            
        elif tipo_token == TipoToken.DECLARACION_ENTIDAD:
            return f"Declaraci√≥n de entidad del tipo: {texto_token}"
            
        elif tipo_token == TipoToken.TIPO_DATO_DOMINIO:
            return f"Tipo de dato del dominio deportivo: {texto_token}"
            
        elif tipo_token == TipoToken.PALABRA_CLAVE:
            return f"Palabra clave del dominio: {texto_token}"
            
        else:
            return "Token reconocido"


def ejecutar_ejemplo_analisis():
    """
    Funci√≥n de demostraci√≥n que ejecuta el analizador con c√≥digo de ejemplo.
    El c√≥digo incluye indentaci√≥n adecuada para mostrar la estructura jer√°rquica.
    """
    codigo_ejemplo_deportivo = [
        '; Programa de gestion deportiva con estructura',
        'Deportista atleta_principal 25 80 75 Futbol Argentina',
        'Lista Deportista lista_competidores',
        'si Comparar(atleta_principal, lista_competidores) > 0 entonces {',
        '    narrar(atleta_principal)',
        '    si atleta_principal > 50 entonces {',
        '        narrar(excelente)',
        '    } endif',
        '} sino {',
        '    narrar(atleta_secundario)',
        '} endif',
        'Repetir(3) [',
        '    narrar(entrenamiento)',
        '    Repetir(2) [',
        '        input(ejercicio)',
        '    ] FinRep',
        '] FinRep',
        'RepetirHasta(Comparar(atleta_principal, lista_competidores) == 0) [',
        '    input(Argentina)',
        '    preparacion',
        '        Deportista corredor1 30 85 90 Atletismo Chile',
        '        Deportista corredor2 28 82 88 Atletismo Peru',
        '    finprep',
        '] FinRepHast',
        'Futbol',
        '    Lista Deportista participantes_torneo',
        '    competencia_mundial',
        '        partido_semifinal',
        '            Argentina vs Brasil',
        '            Comparar(Argentina, Brasil)',
        '            narrar(resultado_partido)',
        '            empate',
        '            Resultado 2 - 1',
        '            listaRes',
        '        finact',
        '        partido_final',
        '            Espa√±a vs Francia',
        '            Comparar(Espa√±a, Francia)',
        '            Resultado 3 - 0',
        '        finact',
        '    ceremonia_medallas',
        'narrar(fin_programa)'
    ]

    analizador_deportivo = AnalizadorLexico(codigo_ejemplo_deportivo)
    analizador_deportivo.analizar_codigo_completo()
    analizador_deportivo.mostrar_tokens_encontrados()


def main():
    """
    Funci√≥n principal que ejecuta solo el ejemplo b√°sico del analizador.
    Para pruebas completas, ejecutar test_explorador.py
    """
    print("üîç ANALIZADOR L√âXICO OLYMPIAC - EJEMPLO B√ÅSICO")
    print("=" * 50)
    print("Para pruebas completas, ejecutar: python test_explorador.py")
    print("=" * 50)
    
    ejecutar_ejemplo_analisis()
    
    print("\n" + "=" * 50)
    print("‚úÖ Ejemplo b√°sico completado")
    print("üìù Para ver todas las pruebas: python test_explorador.py")
    print("=" * 50)


# Punto de entrada principal del programa
if __name__ == "__main__":
    main()
